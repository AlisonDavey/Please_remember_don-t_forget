{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter_3_Document_Similarity.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLBm5wBvx6T3JyNXKi5iEg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2k5O-HGl18z","executionInfo":{"status":"ok","timestamp":1606924680638,"user_tz":-60,"elapsed":50019,"user":{"displayName":"Alison Davey","photoUrl":"","userId":"13559868317612833303"}},"outputId":"33ae76f1-ce8f-45fc-c88f-77b0b919ba4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","%cd '/content/drive/My Drive/Colab Notebooks/Essential-NLP-master/Essential-NLP-master/cisi.zip (Unzipped Files)'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/Colab Notebooks/Essential-NLP-master/Essential-NLP-master/cisi.zip (Unzipped Files)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5aHaiN1UZlWZ"},"source":["# Chapter 3 Document Similarity TF-IDF\n","\n","Exploring the book **Getting Started with Natural Language Processing**\n","\n","https://www.manning.com/books/getting-started-with-natural-language-processing\n","\n","https://www.baeldung.com/cs/ml-similarities-in-text#:~:text=The%20simplest%20way%20to%20compute%20the%20similarity%20between,of%20all%20the%20word%20vectors%20in%20the%20document.\n","\n","The idea behind TF-IDF is that we first compute the number of documents in which a word appears in. If a word appears in many documents, it will be less relevant in the computation of the similarity, and vice versa. We call this value the inverse document frequency or IDF, and we can compute it as:\n","\n","$$\n","idf(word) = log(\\frac{N}{|\\{d \\in C : word \\in d\\}|})\n","$$\n","\n","In the formula, C is the corpus, N is the total number of documents in it, and the denominator is the number of documents that contain our word.\n","\n","We can compute the IDF just once, as a preprocessing step, for each word in our corpus and it will tell us how significant that word is in the corpus itself.\n","\n","At this point, instead of using the raw word counts, we can compute the document vectors by weighing it with the IDF. For each document, weâ€™ll compute the count for each word, transform it into a frequency (that is, dividing the count by the total number of words in the document), and then multiply by the IDF.\n","\n","Given that, the final score for each word will be:\n","$$\n","score(word) = frequency(word) \\cdot idf(word)\n","$$\n"]},{"cell_type":"code","metadata":{"id":"UOkgdUiDvWzR","executionInfo":{"status":"ok","timestamp":1606924681801,"user_tz":-60,"elapsed":51149,"user":{"displayName":"Alison Davey","photoUrl":"","userId":"13559868317612833303"}}},"source":["import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnS6sz_vlvGE"},"source":["def read_documents():\n","    f = open(\"cisi/CISI.ALL\")\n","    merged = \"\"\n","    \n","    for a_line in f.readlines():\n","        if a_line.startswith(\".\"):\n","            merged += \"\\n\" + a_line.strip()\n","        else:\n","            merged += \" \" + a_line.strip()\n","    \n","    documents = {}\n","\n","    content = \"\"\n","    doc_id = \"\"\n","\n","    for a_line in merged.split(\"\\n\"):\n","        if a_line.startswith(\".I\"):\n","            doc_id = a_line.split(\" \")[1].strip()\n","        elif a_line.startswith(\".X\"):\n","            documents[doc_id] = content\n","            content = \"\"\n","            doc_id = \"\"\n","        else:\n","            content += a_line.strip()[3:] + \" \"\n","    f.close()\n","    return documents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iBvHG5qZvZX6","executionInfo":{"status":"ok","timestamp":1606867931776,"user_tz":-60,"elapsed":758,"user":{"displayName":"Alison Davey","photoUrl":"","userId":"13559868317612833303"}},"outputId":"320eac66-f2d0-4ec7-f075-047ec96cf8e4"},"source":["documents = read_documents()\n","print(len(documents))\n","print(documents.get(\"1\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1460\n"," 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n20gCj1hmd0l"},"source":["docs_list = [documents[i] for i in documents.keys()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5cZFzM6l_0k"},"source":["def read_queries():\n","    f = open(\"cisi/CISI.QRY\")\n","    merged = \"\"\n","    \n","    for a_line in f.readlines():\n","        if a_line.startswith(\".\"):\n","            merged += \"\\n\" + a_line.strip()\n","        else:\n","            merged += \" \" + a_line.strip()\n","    \n","    queries = {}\n","\n","    content = \"\"\n","    qry_id = \"\"\n","\n","    for a_line in merged.split(\"\\n\"):\n","        if a_line.startswith(\".I\"):\n","            if not content==\"\":\n","                queries[qry_id] = content\n","                content = \"\"\n","                qry_id = \"\"\n","            qry_id = a_line.split(\" \")[1].strip()\n","        elif a_line.startswith(\".W\") or a_line.startswith(\".T\"):\n","            content += a_line.strip()[3:] + \" \"\n","    queries[qry_id] = content\n","    f.close()\n","    return queries"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cugUexblvfwf","executionInfo":{"status":"ok","timestamp":1606867936678,"user_tz":-60,"elapsed":550,"user":{"displayName":"Alison Davey","photoUrl":"","userId":"13559868317612833303"}},"outputId":"05cc5fc5-72da-4367-d09c-acb709f4c93e"},"source":["queries = read_queries()\n","print(len(queries))\n","print(queries.get(\"1\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["112\n","What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles? \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2EIH6YUkhYmU"},"source":["vectorizer = TfidfVectorizer()\n","\n","def process_tfidf_similarity(base_document, docs_list):\n","  docs_list=[base_document]+docs_list\n","  embeddings = vectorizer.fit_transform(docs_list)\n","  cosine_similarities = cosine_similarity(embeddings[0], embeddings[1:]).flatten()\n","  index = np.argmax(cosine_similarities)\n","\n","  print(\"Most similar document by TF-IDF with the score:\", np.round(cosine_similarities[index],4))\n","  print('query:', base_document)\n","  print('document:',docs_list[index])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6McaILYj3ZV","executionInfo":{"status":"ok","timestamp":1606868198726,"user_tz":-60,"elapsed":695,"user":{"displayName":"Alison Davey","photoUrl":"","userId":"13559868317612833303"}},"outputId":"ded3bf8e-6e6f-4321-c63f-6123e4c6c05d"},"source":["process_tfidf_similarity( queries['20'], docs_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Most similar document by TF-IDF with the score: 0.3164\n","query: Testing automated information systems. \n","document: User Evaluation of Information Retrieval Systems Cleverdon, C.W. While Fairthorne may not have been the first person to recognize it, certainly, for this author, Fairthorne was the first to make explicit the fundamental problems of information retrieval systems, namely the clash between OBNA and ABNO (Only-But-Not-All and All-But-Not-Only). Although it was not until 1958 that the terms occur in Fairthorne's writings, the concept had been discussed in many meetings of the AGARD Documentation Panel and elsewhere.  Originally it was considered that to meet these two requirements, it might be necessary to have two separate systems, and the test of the UNITERM system in 1954 was based on the hypothesis that a 'Marshalling' system (e.g. U.D.C.) was fundamentally different from a 'Retrieval' system (e.g. UNITERM).  While the idea persisted in this form for some time, it gradually evolved into the inverse relationship of recall and precision, which is to say that while it is possible to obtain, of the relevant documents, All-But-Not-Only, or alternatively to obtain Only-But- Not-All, it is not possible to obtain All and Only. \n"],"name":"stdout"}]}]}